{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chapter 16 \n",
    "====\n",
    "\n",
    "## Project two: character-level language modeling in TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 1144k  100 1144k    0     0  2706k      0 --:--:-- --:--:-- --:--:-- 2711k\n"
     ]
    }
   ],
   "source": [
    "! curl -O http://www.gutenberg.org/files/1268/1268-0.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "567 1112917\n",
      "Total Length:  1112350\n",
      "Unique Characters:  80\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "## Reading and processing text\n",
    "with open('1268-0.txt', 'r') as fp:\n",
    "    text=fp.read()\n",
    "    \n",
    "start_indx = text.find('THE MYSTERIOUS ISLAND')\n",
    "end_indx = text.find('End of the Project Gutenberg')\n",
    "print(start_indx, end_indx)\n",
    "\n",
    "text = text[start_indx:end_indx]\n",
    "char_set = set(text)\n",
    "print('Total Length: ', len(text))\n",
    "print('Unique Characters: ', len(char_set))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text encoded shape:  (1112350,)\n",
      "THE MYSTERIOUS    == Encoding ==>  [44 32 29  1 37 48 43 44 29 42 33 39 45 43  1]\n",
      "[33 43 36 25 38 28]   == Reverse ==>  ISLAND\n"
     ]
    }
   ],
   "source": [
    "chars_sorted = sorted(char_set)\n",
    "char2int = {ch:i for i,ch in enumerate(chars_sorted)}\n",
    "char_array = np.array(chars_sorted)\n",
    "\n",
    "text_encoded = np.array(\n",
    "    [char2int[ch] for ch in text],\n",
    "    dtype=np.int32)\n",
    "\n",
    "print('Text encoded shape: ', text_encoded.shape)\n",
    "\n",
    "print(text[:15], '  == Encoding ==> ', text_encoded[:15])\n",
    "print(text_encoded[15:21], '  == Reverse ==> ', ''.join(char_array[text_encoded[15:21]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 -> T\n",
      "32 -> H\n",
      "29 -> E\n",
      "1 ->  \n",
      "37 -> M\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "ds_text_encoded = tf.data.Dataset.from_tensor_slices(text_encoded)\n",
    "\n",
    "for ex in ds_text_encoded.take(5):\n",
    "    print('{} -> {}'.format(ex.numpy(), char_array[ex.numpy()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[44 32 29  1 37 48 43 44 29 42 33 39 45 43  1 33 43 36 25 38 28  1  6  6\n",
      "  6  0  0  0  0  0 40 67 64 53 70 52 54 53  1 51]  ->  74\n",
      "'THE MYSTERIOUS ISLAND ***\\n\\n\\n\\n\\nProduced b'  ->  'y'\n"
     ]
    }
   ],
   "source": [
    "seq_length = 40\n",
    "chunk_size = seq_length + 1\n",
    "\n",
    "ds_chunks = ds_text_encoded.batch(chunk_size, drop_remainder=True)\n",
    "\n",
    "## inspection:\n",
    "for seq in ds_chunks.take(1):\n",
    "    input_seq = seq[:seq_length].numpy()\n",
    "    target = seq[seq_length].numpy()\n",
    "    print(input_seq, ' -> ', target)\n",
    "    print(repr(''.join(char_array[input_seq])), \n",
    "          ' -> ', repr(''.join(char_array[target])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Input (x):  'THE MYSTERIOUS ISLAND ***\\n\\n\\n\\n\\nProduced b'\n",
      "Target (y):  'HE MYSTERIOUS ISLAND ***\\n\\n\\n\\n\\nProduced by'\n",
      "\n",
      " Input (x):  ' Anthony Matonak, and Trevor Carlson\\n\\n\\n\\n'\n",
      "Target (y):  'Anthony Matonak, and Trevor Carlson\\n\\n\\n\\n\\n'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## define the function for splitting x & y\n",
    "def split_input_target(chunk):\n",
    "    input_seq = chunk[:-1]\n",
    "    target_seq = chunk[1:]\n",
    "    return input_seq, target_seq\n",
    "\n",
    "ds_sequences = ds_chunks.map(split_input_target)\n",
    "\n",
    "## inspection:\n",
    "for example in ds_sequences.take(2):\n",
    "    print(' Input (x): ', repr(''.join(char_array[example[0].numpy()])))\n",
    "    print('Target (y): ', repr(''.join(char_array[example[1].numpy()])))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((None, 40), (None, 40)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batch size\n",
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "tf.random.set_seed(1)\n",
    "ds = ds_sequences.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)# drop_remainder=True)\n",
    "\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 256)         20480     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, None, 512)         1574912   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, None, 80)          41040     \n",
      "=================================================================\n",
      "Total params: 1,636,432\n",
      "Trainable params: 1,636,432\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim),\n",
    "        tf.keras.layers.LSTM(\n",
    "            rnn_units, return_sequences=True),\n",
    "        tf.keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "\n",
    "charset_size = len(char_array)\n",
    "embedding_dim = 256\n",
    "rnn_units = 512\n",
    "\n",
    "tf.random.set_seed(1)\n",
    "\n",
    "model = build_model(\n",
    "    vocab_size = charset_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "424/424 [==============================] - 94s 222ms/step - loss: 2.3170\n",
      "Epoch 2/20\n",
      "424/424 [==============================] - 92s 218ms/step - loss: 1.7389\n",
      "Epoch 3/20\n",
      "424/424 [==============================] - 93s 219ms/step - loss: 1.5360\n",
      "Epoch 4/20\n",
      "424/424 [==============================] - 93s 219ms/step - loss: 1.4221\n",
      "Epoch 5/20\n",
      "424/424 [==============================] - 92s 217ms/step - loss: 1.3495\n",
      "Epoch 6/20\n",
      "424/424 [==============================] - 92s 217ms/step - loss: 1.2981\n",
      "Epoch 7/20\n",
      "424/424 [==============================] - 93s 218ms/step - loss: 1.2605\n",
      "Epoch 8/20\n",
      "424/424 [==============================] - 93s 218ms/step - loss: 1.2305\n",
      "Epoch 9/20\n",
      "424/424 [==============================] - 93s 219ms/step - loss: 1.2053\n",
      "Epoch 10/20\n",
      "424/424 [==============================] - 93s 218ms/step - loss: 1.1832\n",
      "Epoch 11/20\n",
      "424/424 [==============================] - 92s 217ms/step - loss: 1.1634\n",
      "Epoch 12/20\n",
      "424/424 [==============================] - 92s 217ms/step - loss: 1.1457\n",
      "Epoch 13/20\n",
      "424/424 [==============================] - 92s 218ms/step - loss: 1.1296\n",
      "Epoch 14/20\n",
      "424/424 [==============================] - 92s 218ms/step - loss: 1.1142\n",
      "Epoch 15/20\n",
      "424/424 [==============================] - 93s 219ms/step - loss: 1.1000\n",
      "Epoch 16/20\n",
      "424/424 [==============================] - 92s 216ms/step - loss: 1.0858\n",
      "Epoch 17/20\n",
      "424/424 [==============================] - 93s 219ms/step - loss: 1.0721\n",
      "Epoch 18/20\n",
      "159/424 [==========>...................] - ETA: 59s - loss: 1.0615"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer='adam', \n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits=True\n",
    "    ))\n",
    "\n",
    "model.fit(ds, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities:  [0.33333334 0.33333334 0.33333334]\n",
      "array([[0, 0, 1, 2, 0, 0, 0, 0, 1, 0]])\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "\n",
    "logits = [[1.0, 1.0, 1.0]]\n",
    "print('Probabilities: ', tf.math.softmax(logits).numpy()[0])\n",
    "\n",
    "samples = tf.random.categorical(\n",
    "    logits=logits, num_samples=10)\n",
    "tf.print(samples.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities:  [0.10650698 0.10650698 0.78698605]\n",
      "array([[2, 0, 2, 2, 2, 0, 1, 2, 2, 0]])\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "\n",
    "logits = [[1.0, 1.0, 3.0]]\n",
    "print('Probabilities: ', tf.math.softmax(logits).numpy()[0])\n",
    "\n",
    "samples = tf.random.categorical(\n",
    "    logits=logits, num_samples=10)\n",
    "tf.print(samples.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The island is open he heard the victory of the\n",
      "Mercy, and brought it into them, and they no longer continue, some on the little man of the felting circle of slopes.\n",
      "\n",
      "The engineer troused, he could not find our companions.\n",
      "\n",
      "\n",
      "\n",
      "Chapter 11\n",
      "\n",
      "At this position, he might just as if his first true to be finished, and he\n",
      "though not more I can this teles.”\n",
      "\n",
      "“Why shall fear line,” answered the reporter, “what a disposal silence was advanced with them, and in masterspon.\n",
      "\n",
      "Before three heights of the\n",
      "Frenchant Heights \n"
     ]
    }
   ],
   "source": [
    "def sample(model, starting_str, \n",
    "           len_generated_text=500, \n",
    "           max_input_length=40,\n",
    "           scale_factor=1.0):\n",
    "    encoded_input = [char2int[s] for s in starting_str]\n",
    "    encoded_input = tf.reshape(encoded_input, (1, -1))\n",
    "\n",
    "    generated_str = starting_str\n",
    "\n",
    "    model.reset_states()\n",
    "    for i in range(len_generated_text):\n",
    "        logits = model(encoded_input)\n",
    "        logits = tf.squeeze(logits, 0)\n",
    "\n",
    "        scaled_logits = logits * scale_factor\n",
    "        new_char_indx = tf.random.categorical(\n",
    "            scaled_logits, num_samples=1)\n",
    "        \n",
    "        new_char_indx = tf.squeeze(new_char_indx)[-1].numpy()    \n",
    "\n",
    "        generated_str += str(char_array[new_char_indx])\n",
    "        \n",
    "        new_char_indx = tf.expand_dims([new_char_indx], 0)\n",
    "        encoded_input = tf.concat(\n",
    "            [encoded_input, new_char_indx],\n",
    "            axis=1)\n",
    "        encoded_input = encoded_input[:, -max_input_length:]\n",
    "\n",
    "    return generated_str\n",
    "\n",
    "tf.random.set_seed(1)\n",
    "print(sample(model, starting_str=\"The island\", \n",
    "             scale_factor=1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictability vs. randomness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities before scaling:         [0.10650698 0.10650698 0.78698604]\n",
      "Probabilities after scaling with 0.5: [0.21194156 0.21194156 0.57611688]\n",
      "Probabilities after scaling with 0.1: [0.31042377 0.31042377 0.37915245]\n"
     ]
    }
   ],
   "source": [
    "logits = np.array([[1.0, 1.0, 3.0]])\n",
    "\n",
    "print('Probabilities before scaling:        ', tf.math.softmax(logits).numpy()[0])\n",
    "\n",
    "print('Probabilities after scaling with 0.5:', tf.math.softmax(0.5*logits).numpy()[0])\n",
    "\n",
    "print('Probabilities after scaling with 0.1:', tf.math.softmax(0.1*logits).numpy()[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The island spoke of heavy torn into the island from the sea.\n",
      "\n",
      "The noise of the inhabitants of the island was to be feared that the colonists had come a project with a straight be put to the bank of the island was the surface of the lake and sulphuric acid, and several supply of her animals. The first stranger carried a sort of accessible to break these screen barrels to their distance from the palisade.\n",
      "\n",
      "“The first huntil,” said the reporter, “and his companions the reporter extended to build a few days a\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "print(sample(model, starting_str=\"The island\", \n",
    "             scale_factor=2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The island\n",
      "glissed in\n",
      "ascercicedly useful? loigeh, Cyrus,\n",
      "Spileots,” henseporvemented\n",
      "House to a left\n",
      "the centlic moment. Tonsense craw.\n",
      "\n",
      "Pencrular ed/ of times,” tading had coflently often above anzand?”\n",
      "\n",
      "“Wat;” then:y.”\n",
      "\n",
      "\n",
      "Ardivify he acpearly, howcovered--he hassime; however, fenquests hen adgents!’.? Let us Neg eqiAl?.\n",
      "\n",
      "GencNal, my surved thirtyin” ou; is Harding; treuths. Osew apartarned. “N,\n",
      "the poltuge of about-but durired with purteg.\n",
      "\n",
      "Chappes wason!\n",
      "\n",
      "Fears,” returned Spilett; “if\n",
      "you tear 8t trung\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "print(sample(model, starting_str=\"The island\", \n",
    "             scale_factor=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
